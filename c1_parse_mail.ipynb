{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import os,pg8000\n",
    "import unicodedata\n",
    "import tarfile\n",
    "import gzip\n",
    "import email, codecs\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gc\n",
    "\n",
    "from config.database import HOST, PORT, USER, PASSWORD, DATABASE\n",
    "\n",
    "import psycopg2"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "os.chdir(\"/mnt/data0/proj_osgeo/data\")\n",
    "db_config=open('./db_config')\n",
    "dbHOST=db_config.readline().split('\\\"')[1]\n",
    "dbUSER=db_config.readline().split('\\\"')[1]\n",
    "dbPASS=db_config.readline().split('\\\"')[1]\n",
    "dbDB=db_config.readline().split('\\\"')[1]\n",
    "db_config.close()\n",
    "conn = pg8000.connect(host=dbHOST,user=dbUSER,password=dbPASS,database=dbDB)\n",
    "conn.commit()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "\n",
    "\n",
    "def read_into_buffer(filename):\n",
    "    buf = bytearray(os.path.getsize(filename))\n",
    "    with open(filename, 'rb') as f:\n",
    "        f.readinto(buf)\n",
    "    f.close()\n",
    "    return buf\n",
    "\n",
    "def readfileline(f):\n",
    "    \n",
    "    try:\n",
    "        return f.readline()\n",
    "    except Exception as e:\n",
    "        #print(f.tell())\n",
    "        f.seek(f.tell()+5, 0)\n",
    "        #print(f.tell())\n",
    "        #print(\"Jump 5\")\n",
    "        return -1\n",
    "    \n",
    "def readfile(path, enco):\n",
    "    try:\n",
    "        with open(path, 'r', encoding= enco) as f:\n",
    "            return f.readlines()\n",
    "    except BaseException as err:\n",
    "        try:\n",
    "            x = []\n",
    "            with open(path, 'r', encoding= enco) as f:\n",
    "                fline = readfileline(f)\n",
    "                while fline != \"\":\n",
    "                    if fline != -1 :\n",
    "                        x.append(fline)\n",
    "                    fline = readfileline(f)\n",
    "                    #print(fline)\n",
    "                return x\n",
    "                    \n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            return None\n",
    "\n",
    "def _decode(b, enco):\n",
    "    try:\n",
    "        return str(b, encoding= enco)\n",
    "    except Exception as e:\n",
    "        return None\n",
    "\n",
    "def decode_data(b, added_encode=None):\n",
    "    \"\"\"\n",
    "    bytedecoding\n",
    "    :param bytes:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    #def _decode(b, enco):\n",
    "    #    try:\n",
    "    #        return str(b, encoding= enco)\n",
    "    #    except Exception as e:\n",
    "    #        return None\n",
    "\n",
    "    encodes = ['utf-8', 'ascii', \"base64\"]\n",
    "    if added_encode:\n",
    "        encodes = [added_encode] + encodes\n",
    "    for enco in encodes:\n",
    "        str_data = _decode(b, enco)\n",
    "        if str_data != None:\n",
    "            return str_data\n",
    "    return None\n",
    "   "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    " \n",
    "# Converts text into ascii to fix weird characters\n",
    "def asciiCodify(s):\n",
    "    try:\n",
    "        u = unicode(s, errors=\"replace\")\n",
    "        v = u.encode(\"ascii\", \"replace\")\n",
    "        return v\n",
    "    except:\n",
    "        # s is empty\n",
    "        return \"EMPTY\"\n",
    "# Fix any characters that might mess up script\n",
    "def escape(s):\n",
    "    return (s).replace(\"'\", \"''\").replace('%', '%%').replace('<','').replace('>','')\n",
    "    \n",
    "# Counts number of lines in file\n",
    "def file_line_number(file):\n",
    "    for i, l in enumerate(file):\n",
    "        pass\n",
    "    return i + 1"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "#print(readfile(\"./raw/mapserver-commits/2008-December.txt\", 'utf-8'))"
   ],
   "outputs": [],
   "metadata": {
    "scrolled": true,
    "tags": []
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "def getMonthContent(path):\n",
    "    print(path)\n",
    "    messages = []\n",
    "    messageText=\"\"\n",
    "    try:\n",
    "        #fileContentIn = codecs.open(path)\n",
    "        #global ContentIn\n",
    "        #ContentIn=[decode_data(x) for x in fileContentIn.readlines()]\n",
    "        #ContentIn = fileContentIn.readlines()\n",
    "\n",
    "\n",
    "        encodes = ['utf-8', 'ascii', \"base64\", 'ANSI', 'GBK', 'utf-16', 'utf-32']\n",
    "        for enco in encodes:\n",
    "            ContentIn = readfile(path, enco)\n",
    "            if ContentIn is not None:\n",
    "                #print(\"File read Success:\"+path)\n",
    "                break\n",
    "        \n",
    "        #print(ContentIn)\n",
    "        #fileContentIn.close()\n",
    "        if ContentIn is None:\n",
    "            raise ValueError(\"Unknown File Coding of file:\" + path)\n",
    "        #messages=[]\n",
    "        \n",
    "        for i in range(len(ContentIn)):\n",
    "            if (i+1 < len(ContentIn) and ContentIn[i].startswith(\"From \") and ContentIn[i+1].startswith(\"From:\")) or (i+1==len(ContentIn)):\n",
    "                if len(messageText):\n",
    "                    message = email.message_from_string(messageText)\n",
    "                    #print( \"Message\",\"From\", message[\"from\"], \"To\", message[\"to\"], \"ID\", message[\"message-id\"], \"Thread\", message[\"references\"])\n",
    "                    messages.append(message)\n",
    "                messageText = \"\"\n",
    "            else:\n",
    "                messageText += ContentIn[i]\n",
    "        #print (\"there are\", len(messages), \" messages\",\" \",path)\n",
    "        #global totalMessages\n",
    "        #totalMessages = totalMessages + len(messages)\n",
    "    except BaseException as e:\n",
    "        print(e)\n",
    "        \n",
    "    if len(messages) == 0:\n",
    "        return [\"\"]\n",
    "    return messages"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "def add_aliase(aliase_id, personname, mailaddress, source):\n",
    "\n",
    "    try:\n",
    "        db = psycopg2.connect(\n",
    "            host=HOST,\n",
    "            port=PORT,\n",
    "            user=USER,\n",
    "            password=PASSWORD,\n",
    "            database=DATABASE)\n",
    "            #charset='utf8')\n",
    "        cursor = db.cursor()\n",
    "    except Exception as e:\n",
    "        logging.error(\"Database connect error:%s\" % e)\n",
    "\n",
    "    #aliase_id, mailaddress = aliase.replace('<', ' ').replace('>', ' ').split()\n",
    "    aliase_id = aliase_id.replace('\\'','\\'\\'')\n",
    "    sql_aliase = \"\"\"INSERT INTO aliase(aliase_id, personname, mailaddress, source)\n",
    "                                        values('%s', '%s', '%s', '%s')\"\"\" % (aliase_id, personname, mailaddress, source)\n",
    "    try:\n",
    "        db.commit()\n",
    "        cursor.execute(sql_aliase)\n",
    "        db.commit()\n",
    "    except Exception as err:\n",
    "        sql_aliase = \"\"\"UPDATE aliase SET personname='%s', mailaddress='%s', source='%s' WHERE aliase_id='%s' \"\"\" % (personname, mailaddress, source, aliase_id)\n",
    "        #print(err)\n",
    "        pass\n",
    "    return aliase_id"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "def checkAliase(conn, messages):\n",
    "    \n",
    "    cursor = conn.cursor()\n",
    "    \n",
    "    #aliases = {}\n",
    "    #cursor.execute(\"select personname, mailaddress, aliase_id from aliase\")\n",
    "    #result=cursor.fetchall()\n",
    "    #for personname, mailaddress, aliase_id in result:\n",
    "    #    aliases[personname, mailaddress] = aliase_id \n",
    "    \n",
    "    #unknownAliases = set()\n",
    "    for message in messages:\n",
    "        if \"from\" in message:\n",
    "            personname = email.utils.parseaddr(message[\"from\"])[0]\n",
    "            #personname = asciiCodify(personname)  #不可用\n",
    "            mailaddress = message[\"from\"].split('(')[0].replace(' at ','@')\n",
    "            #if  (personname, mailaddress) not in aliases:\n",
    "            #    if (personname, mailaddress) not in unknownAliases :\n",
    "            #        unknownAliases.add( (personname, mailaddress) )\n",
    "            add_aliase(escape(personname+'_'+mailaddress), escape(personname), escape(mailaddress), \"email\")        \n",
    "            \n",
    "        \n",
    "#    if len(unknownAliases) > 0:\n",
    "#        \n",
    "#        sql = \"insert into aliase (personname, mailaddress, aliase_id, source) values \" + \\\n",
    "#       \", \".join([\"('\"+ escape(personname) +\"','\" + escape(mailaddress) + \"','\" + escape(personname+'_'+mailaddress) + \"','\"+ \"email\" +\"')\" \n",
    "#               for personname, mailaddress in unknownAliases]) + \\\n",
    "#            \" returning personname, mailaddress, aliase_id\"\n",
    "#               \n",
    "#        try:\n",
    "#            cursor.execute(sql)\n",
    "#            result=cursor.fetchall()\n",
    "\n",
    "#            for personname, mailaddress, aliase_id in result:\n",
    "#                aliases[personname, mailaddress] = aliase_id\n",
    "#        except pg8000.ProgrammingError as e:\n",
    "#            #print message\n",
    "#            print (\"insert error\")\n",
    "#            print (e)\n",
    "\n",
    "#        conn.commit()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "def checkThread(conn, messages, pjname):\n",
    "    cursor = conn.cursor()\n",
    "    \n",
    "    threads = set()\n",
    "    cursor.execute(\"select thread_id, project_id from thread\")\n",
    "    result=cursor.fetchall()\n",
    "    for thread_id, project_id in result:\n",
    "        threads.add((thread_id, project_id))\n",
    "        \n",
    "    unknownThreads = set()\n",
    "    for message in messages:\n",
    "        if \"references\" in message:\n",
    "            thread_id = escape(message[\"references\"].split()[-1]+\"__\"+pjname)\n",
    "            project_id = escape(pjname)\n",
    "            if (thread_id, project_id) not in threads:\n",
    "                if (thread_id, project_id) not in unknownThreads:\n",
    "                    unknownThreads.add((thread_id, project_id))\n",
    "        #else:\n",
    "            #print(\"No threading\")\n",
    "    \n",
    "    if len(unknownThreads) > 0:\n",
    "        #print(unknownThreads)\n",
    "        sql = \"insert into thread (thread_id, thread_name, project_id) values \" + \\\n",
    "                \",\".join([\"('\"+ thread_id+\"','\" + project_id+thread_id.split('@')[0]+\"','\" + project_id + \"')\"\n",
    "                            for thread_id, project_id in unknownThreads]) + \\\n",
    "                \" returning thread_id, project_id\"\n",
    "        \n",
    "        try:\n",
    "            cursor.execute(sql)\n",
    "            result=cursor.fetchall()\n",
    "            for thread_id, project_id in result:\n",
    "                threads.add((thread_id, project_id))\n",
    "        except pg8000.ProgrammingError as e:\n",
    "            #print message\n",
    "            print (\"insert error\")\n",
    "            print (e)\n",
    "            \n",
    "        conn.commit()\n",
    "    "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "def saveMessagetocsv(messages, csv_file):\n",
    "    \n",
    "    \n",
    "    message_id = []\n",
    "    thread_id = []\n",
    "    author_aliase_id = []\n",
    "    author_name = []\n",
    "    message_text = []\n",
    "    timestamp = []\n",
    "    \n",
    "    for message in messages:\n",
    "        #flag = False\n",
    "        \n",
    "        if \"from\" in message:\n",
    "            personname = email.utils.parseaddr(message[\"from\"])[0]\n",
    "            #personname = asciiCodify(personname)  #不可用\n",
    "            mailaddress = message[\"from\"].split('(')[0].replace(' at ','@')\n",
    "\n",
    "            author_aliase_id.append(personname+'_'+mailaddress)\n",
    "            author_name.append(personname)\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            if \"message-id\" in message:\n",
    "                message_id.append(escape(message[\"message-id\"]))\n",
    "        except BaseExcepton as e:\n",
    "            print(e)\n",
    "            message_id.append(\"\")\n",
    "            \n",
    "\n",
    "        if \"references\" in message:\n",
    "            thread_id.append(escape(message[\"references\"].split()[-1]))\n",
    "        else:\n",
    "            thread_id.append('')\n",
    "\n",
    "        message_text.append(message.__str__())\n",
    "\n",
    "        if \"date\" in message:\n",
    "            time_format = \"%a %b %d %H:%M:%S %Y\"\n",
    "            try:\n",
    "                tsp = time.strptime(message[\"date\"], time_format)\n",
    "            except ValueError as e:\n",
    "                try:\n",
    "                    time_format =  \"%a %d %b %Y %H:%M:%S %z \"\n",
    "                    tsp = time.strptime(message[\"date\"].split('(')[0].replace(\",\",\"\"), time_format)\n",
    "                except ValueError as e:\n",
    "                    try:\n",
    "                        time_format =  \"%a %d %b %Y %H:%M:%S %z\"\n",
    "                        tsp = time.strptime(message[\"date\"].split('(')[0].replace(\",\",\"\"), time_format)\n",
    "                    except ValueError as e:\n",
    "                        try:\n",
    "                            time_format =  \"%d %b %Y %H:%M:%S %z\"\n",
    "                            tsp = time.strptime(message[\"date\"].split('(')[0].replace(\",\",\"\"), time_format)\n",
    "                        except ValueError as e:\n",
    "                            try:\n",
    "                                time_format = \"%a %d %b %Y %H:%M:%S\"\n",
    "                                tsp = time.strptime(message[\"date\"].split('(')[0][:-5].replace(\",\",\"\"), time_format)\n",
    "                            except ValueError as e:\n",
    "                                try:\n",
    "                                    time_format = \"%a %d %b %Y %H:%M \"\n",
    "                                    tsp = time.strptime(message[\"date\"].split('(')[0][:-5].replace(\",\",\"\"), time_format)\n",
    "                                except BaseException as e:\n",
    "                                    print(e)\n",
    "                                    #flag = True\n",
    "                                    timestamp.append('')\n",
    "                                    continue\n",
    "            \n",
    "                \n",
    "            time_format = \"%Y-%m-%d %H:%M:%S\"\n",
    "            timestamp.append(time.strftime(time_format, tsp))\n",
    "        else:\n",
    "            timestamp.append('')\n",
    "            \n",
    "        conn.commit()\n",
    "        #sql = \"insert into message (message_id, thread_id, author_aliase_id, author_name, message_text, timestamp) values \" + \\\n",
    "        #        \",('\"+ message_id[-1]+ \"','\"+ thread_id[-1]+ \"','\"+ author_aliase_id[-1]+ \"','\"+ author_name[-1]+ \"','\"+ '' + \"','\"+ timestamp[-1]+ \"'),\"+ \\\n",
    "        #        \"returning message_id\"\n",
    "        #print(sql)\n",
    "        #try:\n",
    "        #    cursor.execute(sql)\n",
    "            \n",
    "        #except pg8000.ProgrammingError as e:\n",
    "            #print message\n",
    "        #    print (\"insert error\")\n",
    "        #    print (e)\n",
    "        #    print (sql)\n",
    "        conn.commit()\n",
    "        \n",
    "    df_message = pd.DataFrame(columns =[\"message_id\", \"thread_id\", \"author_aliase_id\", \"author_name\", \"receivers_name\", \"message_text\", \"timestamp\" ])\n",
    "    df_message[\"message_id\"] = pd.Series(message_id)\n",
    "    df_message[\"thread_id\"] = pd.Series(thread_id)\n",
    "    df_message[\"author_aliase_id\"] = pd.Series(author_aliase_id)\n",
    "    df_message[\"author_name\"] = pd.Series(author_name)\n",
    "    df_message[\"timestamp\" ] = pd.Series(timestamp)\n",
    "    df_message[\"message_text\" ] = pd.Series(message_text)\n",
    "    \n",
    "    df_message.to_csv(csv_file)\n",
    "    "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "# Main Function\n",
    "\n",
    "# Unzip the txt files\n",
    "DIR = './raw'\n",
    "DIR_csv = './csv'\n",
    "filelist_in=os.listdir(DIR)\n",
    "\n",
    "\n",
    "################################Check Project Exist\n",
    "\n",
    "cursor = conn.cursor()\n",
    "conn.commit()\n",
    "\n",
    "projs = set()\n",
    "cursor.execute(\"select proj_id from project\")\n",
    "result=cursor.fetchall()\n",
    "for proj_id in result:\n",
    "    print(proj_id)\n",
    "    projs.add(proj_id[0])\n",
    "conn.commit()\n",
    "    \n",
    "#for element in filelist_in[:1]:\n",
    "for element in filelist_in:\n",
    "    element_messages = []\n",
    "    # Project name and write the log\n",
    "    list_out=open(\"filelist.txt\",\"w+\")\n",
    "    if (\"-commit\" in element) or (\"-dev\" in element)or (\"-psc\" in element)or (\"-discuss\" in element):\n",
    "        pjname = element.split(\"-\")[0]\n",
    "    elif (\"_commit\" in element) or (\"_dev\" in element):\n",
    "        pjname = element.split(\"_\")[0]\n",
    "    else:\n",
    "        pjname = element.split()[0]\n",
    "    list_out.write(DIR+\"/\"+element+\"\\n\")\n",
    "    list_out.close()\n",
    "    \n",
    "    if pjname not in projs:\n",
    "        sql = \"insert into project (proj_id) values \" + \"('\"+ escape(pjname) + \"')\" \n",
    "        \n",
    "        cursor.execute(sql)\n",
    "        conn.commit()\n",
    "        projs.add(pjname)\n",
    "        \n",
    "    # UNZIP ALL .gz files, run once\n",
    "    #gzlist = os.listdir(DIR+\"/\"+element)\n",
    "\n",
    "    #for f_gz in gzlist:\n",
    "    #    f_gz_dir = DIR+\"/\"+element+\"/\"+f_gz\n",
    "    #    print(f_gz_dir)\n",
    "    #    if not os.path.exists(DIR+\"/\"+element+\"/\"+\"txtfile\"):\n",
    "    #        os.makedirs(DIR+\"/\"+element+\"/\"+\"txtfile\")\n",
    "    #    command = \"gunzip \"+f_gz_dir+' '+DIR+\"/\"+element+\"/txtfile/\"\n",
    "    #    print(command)\n",
    "    #    os.system(command)\n",
    " \n",
    "    txtlist = os.listdir(DIR+\"/\"+element)\n",
    "    for file_month in txtlist:\n",
    "        \n",
    "        messages = getMonthContent(DIR+\"/\"+element+'/'+file_month)\n",
    "        #print(len(messages))\n",
    "        \n",
    "        try:\n",
    "            conn.commit()\n",
    "            checkAliase(conn, messages)\n",
    "            checkThread(conn, messages, pjname)\n",
    "            csv_path = DIR_csv+\"/\"+element+'/'\n",
    "            if not os.path.exists(csv_path):\n",
    "                os.makedirs(csv_path)\n",
    "            csv_file = csv_path+file_month.replace(\".txt\",'')+\".csv\"\n",
    "            saveMessagetocsv( messages, csv_file)\n",
    "        except BaseException as e:\n",
    "            print(e)\n",
    "        element_messages.extend(messages)\n",
    "    csv_file = csv_path+element+\"_all.csv\"    \n",
    "    saveMessagetocsv( element_messages, csv_file)\n",
    "    \n",
    "        #Only Superuser can do\n",
    "        #conn.commit()\n",
    "        #sql = \"COPY message(message_id, thread_id, author_aliase_id, author_name, message_text, timestamp) FROM\" + \\\n",
    "        #        \"'\"+ csv_file+ \"' DELIMITER ',' CSV HEADER\" \n",
    "        #cursor.execute(sql)\n",
    "        #conn.commit()\n",
    "    gc.collect()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['postgis']\n",
      "['gdal']\n",
      "['grass']\n",
      "['fdo-internals']\n",
      "['mapguide-internals']\n",
      "['osgeo4w']\n",
      "['fdo']\n",
      "['zoo-psc']\n",
      "['geos']\n",
      "['gvsig']\n",
      "['koop']\n",
      "['jts topology suite']\n",
      "['mapserver']\n",
      "['qgis desktop']\n",
      "['qgis']\n",
      "['geoserver']\n",
      "['proj']\n",
      "['gc2/vidi']\n",
      "['geotools']\n",
      "['mesh data abstraction layer (mdal)']\n",
      "['mobilitydb']\n",
      "['ossim (open source software image map)']\n",
      "['portable gis']\n",
      "['team engine']\n",
      "['mobility db']\n",
      "['esa-nasa worldwind']\n",
      "['first draft gis']\n",
      "['get-it – geoinformation enabling toolkit starterkit®']\n",
      "['lerc limited error raster compression']\n",
      "['perfecttin']\n",
      "['deegree']\n",
      "['geowave']\n",
      "['geonetwork']\n",
      "['pycsw']\n",
      "['geonode']\n",
      "['osgeolive']\n",
      "['openlayers']\n",
      "['geowebcache']\n",
      "['mapbender']\n",
      "['pywps']\n",
      "['geomoose']\n",
      "['gdal/ogr']\n",
      "['geoext']\n",
      "['pygeoapi']\n",
      "['geomajas']\n",
      "['istsos']\n",
      "['geostyler']\n",
      "['open data cube']\n",
      "['mdal']\n",
      "['actinia']\n",
      "['owslib']\n",
      "['ossim']\n",
      "['pgrouting']\n",
      "['loader']\n",
      "['geohealthcheck']\n",
      "['portable-gis']\n",
      "['teamengine']\n",
      "['bezitopo']\n",
      "['eoxserver']\n",
      "['nasaworldwind']\n",
      "['firstdraftgis']\n",
      "['geomesa']\n",
      "['geopaparazzi']\n",
      "['get-it']\n",
      "['gisquick']\n",
      "['jtstopologysuite']\n",
      "['leaflet']\n",
      "['lerc']\n",
      "['pdal']\n",
      "['proj-jni']\n",
      "['rasterframes']\n",
      "['tegola']\n",
      "['terraformer']\n",
      "['geotrellis']\n",
      "['pronto raster']\n",
      "['geoserver-client-php']\n",
      "['wradlib']\n",
      "['oskari']\n",
      "./raw/openlayers-dev/2017-January.txt.gz\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 3, got 1)",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-9b744ff2144f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     61\u001b[0m         \u001b[0;31m#try:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m         \u001b[0mcheckAliase\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m         \u001b[0mcheckThread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpjname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0mcsv_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDIR_csv\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"/\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0melement\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'/'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-11-1c40f8da88e7>\u001b[0m in \u001b[0;36mcheckAliase\u001b[0;34m(conn, messages)\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;31m#cursor.execute(\"select personname, mailaddress, aliase_id from aliase\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;31m#result=cursor.fetchall()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mpersonname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmailaddress\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maliase_id\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0maliases\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpersonname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmailaddress\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maliase_id\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: not enough values to unpack (expected 3, got 1)"
     ]
    }
   ],
   "metadata": {
    "scrolled": true,
    "tags": []
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print(messages[-1])\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "From: tim at qgis.org (Tim Sutton)\n",
      "Date: Mon, 1 May 2017 01:03:17 +0200\n",
      "Subject: [Qgis-developer] 2017 QGIS Grant Proposals final results\n",
      "Message-ID: <CADwz+dWYTX=Xn1FMM_zYxxjNhjb=K-S0=0r1M-4kQuptUnjxeQ@mail.gmail.com>\n",
      "\n",
      "Hi All\n",
      "\n",
      "Thanks for your patience while you waited for us to prepare the final\n",
      "results for the grant proposals. I hope it was worth the wait since we\n",
      "managed to make some more funds available to support more than the planned\n",
      "EUR 20,000 of proposals.  Read all about the successful proposals here:\n",
      "\n",
      "http://blog.qgis.org/2017/04/30/qgis-grant-programme-2-results/\n",
      "\n",
      "\n",
      "Regards\n",
      "\n",
      "Tim\n",
      "\n",
      "-- \n",
      "\n",
      "\n",
      "\n",
      "*Tim Sutton*\n",
      "QGIS Project Steering Committee Chair\n",
      "tim at qgis.org\n",
      "-------------- next part --------------\n",
      "An HTML attachment was scrubbed...\n",
      "URL: <http://lists.osgeo.org/pipermail/qgis-developer/attachments/20170501/9626c4cd/attachment.html>\n",
      "\n"
     ]
    }
   ],
   "metadata": {
    "tags": []
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "message[-1].as_bytes()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "messages[0][\"date\"]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "messages[1][\"from\"].split('(')[0]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "email.utils.parseaddr(messages[10][\"from\"])[0]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print(messages[0][\"message-id\"])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df_message = pd.DataFrame(columns =[\"message_id\", \"thread_id\", \"author_aliase_id\", \"author_name\", \"receivers_name\", \"message_text\", \"timestamp\" ])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df_message"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "message_id = []\n",
    "thread_id = []\n",
    "author_aliase_id = []\n",
    "author_name = []\n",
    "message_text = []\n",
    "timestamp = []"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print(messages[0][\"references\"])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "for message in messages:\n",
    "    \n",
    "    if \"from\" in message:\n",
    "        author_aliase_id.append(message[\"from\"].split('(')[0])\n",
    "        author_name.append(email.utils.parseaddr(message[\"from\"])[0])\n",
    "    else:\n",
    "        continue\n",
    "        \n",
    "    message_id.append(escape(message[\"message-id\"]))\n",
    "    \n",
    "    if \"references\" in message:\n",
    "        thread_id.append(escape(message[\"references\"].split()[-1]))\n",
    "    else:\n",
    "        thread_id.append('')\n",
    "    \n",
    "    message_text.append(message.__str__())\n",
    "    \n",
    "    if \"date\" in message:\n",
    "        timestamp.append(message[\"date\"])\n",
    "    else:\n",
    "        timestamp.append('')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df_message[\"message_id\"] = pd.Series(message_id)\n",
    "df_message[\"thread_id\"] = pd.Series(thread_id)\n",
    "df_message[\"author_aliase_id\"] = pd.Series(author_aliase_id)\n",
    "df_message[\"author_name\"] = pd.Series(author_name)\n",
    "df_message[\"message_text\" ] = pd.Series(message_text)\n",
    "df_message[\"timestamp\" ] = pd.Series(timestamp)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df_message"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "np.array([message_id, thread_id, author_aliase_id, author_name, message_text, timestamp])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "98373a4284e4a564d4f2df06473808b29be6466d133612bf3acd704edfd754d1"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.6.13 64-bit ('3.6.13': pyenv)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}